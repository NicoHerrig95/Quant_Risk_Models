{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dn3dD6ja2FS"
      },
      "source": [
        "# Long-short-term-Memory Mixture Density Network (LSTM-MDN) for Value-at-Risk forecasting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H55oj9F1R7VE"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bndXPnuaxLr",
        "outputId": "bda5bce5-a4d3-4e6f-e6b6-7fe12ff0cb6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-mdn-layer\n",
            "  Downloading keras-mdn-layer-0.3.0.tar.gz (6.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: keras-mdn-layer\n",
            "  Building wheel for keras-mdn-layer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-mdn-layer: filename=keras_mdn_layer-0.3.0-py3-none-any.whl size=7038 sha256=06274b3c87a9d4ffd1c90ef1c89dff8d4426f1ea89386484b709e1df27825644\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/66/f8/9c196fe00f45d189c9e3b12f0341aa8aa33b657eb5b669465f\n",
            "Successfully built keras-mdn-layer\n",
            "Installing collected packages: keras-mdn-layer\n",
            "Successfully installed keras-mdn-layer-0.3.0\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Dependencies: Packages\n",
        "\"\"\"\n",
        "\n",
        "!pip install keras-mdn-layer # installing MDN layer for keras API in Google Colab\n",
        "\n",
        "# import the common\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# reproducibilty imports\n",
        "import random as rn\n",
        "import os\n",
        "\n",
        "# import TensorFlow and Keras API\n",
        "import tensorflow as tf\n",
        "from tensorflow_probability import distributions as tfd\n",
        "from tensorflow.keras.layers import Input, InputLayer, Dense, Activation, Concatenate, LSTM, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow_probability import distributions as tfd\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "import mdn # keras-mdn-layer\n",
        "\n",
        "# TF callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
        "tensorboard = TensorBoard(log_dir='tbdir/', histogram_freq=0, write_graph=True, write_images=False)\n",
        "mon = EarlyStopping(monitor='loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "\n",
        "\n",
        "# Data download\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O2_Ljz2tnGwa"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "REPRODUCIBILITY\n",
        "\"\"\"\n",
        "\n",
        "# seed setting & reproducibility\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
        "np.random.seed(6969)\n",
        "rn.seed(6969)\n",
        "tf.random.set_seed(6969)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Fna18ryN309s"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "PARAMETERS & STOCKS\n",
        "\"\"\"\n",
        "\n",
        "# list of stocks\n",
        "stocks = [\"^GSPC\", \"^FTSE\", \"^STOXX50E\"]\n",
        "\n",
        "\n",
        "# Rolling window (d)\n",
        "d = 10\n",
        "\n",
        "\n",
        "# start date and end date of testing period\n",
        "# shall be the same as in the \"initialisation.R\" script\n",
        "test_start_date = \"2021-01-01\"\n",
        "test_end_date = \"2022-12-31\"\n",
        "\n",
        "\n",
        "# indicating on wheter results shall be downloaded as .csv\n",
        "save_results = True\n",
        "period_appendix = \"_covid\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UFuzY8-5Rnj8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "UTILITIES: Custom functions\n",
        "\"\"\"\n",
        "\n",
        "# function to transform data frame to input data for neural network\n",
        "def df_to_X_y(df, window_size = 10):\n",
        "  df_as_np = df.to_numpy()\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  for i in range(len(df_as_np) - window_size):\n",
        "    row = [[a] for a in df_as_np[i:i+window_size]]\n",
        "    X.append(row)\n",
        "    label = df_as_np[i + window_size]\n",
        "    y.append(label)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Functions complimentaring the MDN package\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "get_mixture_loss_func_REGULARIZED\n",
        "- a loss function for MDN models which include a regularization term (L2-norm)\n",
        "to the negative log-likelihood.\n",
        "Lambda parameter is set to 20% as default.\n",
        "\"\"\"\n",
        "def get_mixture_loss_func_REGULARIZED(output_dim, num_mixes, lambda_reg = 0.2):\n",
        "    \"\"\"Construct a loss functions for the MDN layer parametrised by number of mixtures.\"\"\"\n",
        "    # Construct a loss function with the right number of mixtures and outputs\n",
        "    def mdn_loss_func(y_true, y_pred):\n",
        "        # Reshape inputs in case this is used in a TimeDistribued layer\n",
        "        y_pred = tf.reshape(y_pred, [-1, (2 * num_mixes * output_dim) + num_mixes], name='reshape_ypreds')\n",
        "        y_true = tf.reshape(y_true, [-1, output_dim], name='reshape_ytrue')\n",
        "        # Split the inputs into paramaters\n",
        "        out_mu, out_sigma, out_pi = tf.split(y_pred, num_or_size_splits=[num_mixes * output_dim,\n",
        "                                                                         num_mixes * output_dim,\n",
        "                                                                         num_mixes],\n",
        "                                             axis=-1, name='mdn_coef_split')\n",
        "        # Construct the mixture models\n",
        "        cat = tfd.Categorical(logits=out_pi)\n",
        "        component_splits = [output_dim] * num_mixes\n",
        "        mus = tf.split(out_mu, num_or_size_splits=component_splits, axis=1)\n",
        "        sigs = tf.split(out_sigma, num_or_size_splits=component_splits, axis=1)\n",
        "        coll = [tfd.MultivariateNormalDiag(loc=loc, scale_diag=scale) for loc, scale\n",
        "                in zip(mus, sigs)]\n",
        "        mixture = tfd.Mixture(cat=cat, components=coll)\n",
        "        loss = mixture.log_prob(y_true)\n",
        "        loss = tf.negative(loss)\n",
        "        loss = tf.reduce_mean(loss)\n",
        "\n",
        "        # regularization\n",
        "        # L2 norm\n",
        "        W = tf.math.reduce_sum(tf.math.square([out_pi]))\n",
        "        loss = loss + (W * lambda_reg)\n",
        "\n",
        "        return loss\n",
        "\n",
        "              # Actually return the loss function\n",
        "    with tf.name_scope('MDN'):\n",
        "        return mdn_loss_func\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "function for decomposing results of MDN layer\n",
        "OUTPUT -> mu-array, sigma-array, pi-array\n",
        "Default for components of mixture distribution is 2\n",
        "\"\"\"\n",
        "def get_outputs(predictions,\n",
        "                   N_MIXES = 2,\n",
        "                   OUTPUT_DIMS = 1):\n",
        "  mus = np.apply_along_axis((lambda a: a[:N_MIXES*OUTPUT_DIMS]), 1, predictions)\n",
        "  sigs = np.apply_along_axis((lambda a: a[N_MIXES*OUTPUT_DIMS:2*N_MIXES*OUTPUT_DIMS]), 1, predictions)\n",
        "  pis = np.apply_along_axis((lambda a: mdn.softmax(a[-N_MIXES:])), 1, predictions)\n",
        "\n",
        "  return(mus, sigs, pis)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "REQUIRES: get_outputs (custom function)\n",
        "custom function for generating parameter predictions\n",
        "using MDN layer\n",
        "\"\"\"\n",
        "def MDN_predict(model, test_data, N_MIXES = 2):\n",
        "\n",
        "  # empty dictionary for storing predictions\n",
        "  out = {\"mu\":[],\n",
        "       \"sigma\":[],\n",
        "       \"pi\":[]}\n",
        "\n",
        "\n",
        "  # prediction distribution parameters\n",
        "  predictions = model.predict(test_data)\n",
        "\n",
        "  # output order is mu -> sigma -> pi\n",
        "  out[\"mu\"] = get_outputs(predictions, N_MIXES = N_MIXES)[0]\n",
        "  out[\"sigma\"] = get_outputs(predictions, N_MIXES = N_MIXES)[1]\n",
        "  out[\"pi\"] = get_outputs(predictions, N_MIXES = N_MIXES)[2]\n",
        "\n",
        "\n",
        "  return(out)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Function for converting predictions to a pandas.DataFrame object\n",
        "which can be used for extraction as file\n",
        "\"\"\"\n",
        "def dataframe_converter(predictions, N_MIXES = 2):\n",
        "  k = 0\n",
        "\n",
        "  # generating empty data frames\n",
        "  if N_MIXES == 2:\n",
        "    out = pd.DataFrame({\"mu1\":[],\n",
        "                      \"mu2\":[],\n",
        "                      \"sigma1\":[],\n",
        "                      \"sigma2\":[],\n",
        "                      \"pi1\":[],\n",
        "                      \"pi2\":[]})\n",
        "  elif N_MIXES == 3:\n",
        "    out = pd.DataFrame({\"mu1\":[],\n",
        "                         \"mu2\":[],\n",
        "                         \"mu3\":[],\n",
        "                         \"sigma1\":[],\n",
        "                         \"sigma2\":[],\n",
        "                         \"sigma3\":[],\n",
        "                         \"pi1\":[],\n",
        "                         \"pi2\":[],\n",
        "                         \"pi3\":[]})\n",
        "\n",
        "\n",
        "  # filling data frame with predictions\n",
        "  for j in [\"mu\", \"sigma\", \"pi\"]:\n",
        "    for i in range(0,N_MIXES):\n",
        "      out.iloc[:,k] = predictions[j][:,i]\n",
        "      k = k+1\n",
        "\n",
        "  return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCfMTErxkPna"
      },
      "source": [
        "## Parameters\n",
        "Defining parameters and list for stock data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g2nO2CKnbC0o"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Data Download\n",
        "\"\"\"\n",
        "\n",
        "# file path to the Github repository where data files are stored\n",
        "file_path = 'https://raw.githubusercontent.com/NicoHerrig95/Quant_Risk_Models/main/data_files/'\n",
        "\n",
        "\n",
        "# storing raw data from github repo\n",
        "Data = {} # empty dictionary\n",
        "for x in stocks:\n",
        "    # storing each file in dictionary\n",
        "    Data[x] = pd.read_csv(file_path + x + \".csv\")\n",
        "    # removing redundand columns\n",
        "    Data[x].drop(columns = [\"Unnamed: 0\"], axis=1, inplace=True)\n",
        "    Data[x].date = pd.to_datetime(Data[x].date)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbxcxQVkTFh9",
        "outputId": "6038e3d0-9791-46b6-dd03-a41a8fe776a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.44 µs\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Data Transformation\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "%time\n",
        "# function for splitting a data frame into train set, test set and evaluation set\n",
        "def data_transform_split(df,\n",
        "                         test_start,\n",
        "                         test_end,\n",
        "                         window_size = d):\n",
        "\n",
        "\n",
        "\n",
        "  # calculating actual start for start date\n",
        "  test_start_index = df[(df['date'] > test_start_date)].index.min() # original start index\n",
        "  test_start_index = test_start_index - d # adjusted start index for batch size\n",
        "  test_start_date_new =  df['date'].iloc[test_start_index]\n",
        "\n",
        "  test_data = df[(df['date'] >= test_start_date_new) & (df['date'] <= test_end_date)]\n",
        "  dates_test = test_data[\"date\"].copy()\n",
        "\n",
        "  X_test, y_test = df_to_X_y(df = test_data[\"R\"],\n",
        "                            window_size=d)\n",
        "\n",
        "\n",
        "  end_valid_index = df[(df['date'] < test_start_date_new)].index.max()\n",
        "  end_train_index = int(np.floor(end_valid_index * 0.9))\n",
        "\n",
        "  train_data = df.iloc[1:end_train_index].reset_index(drop=True)\n",
        "\n",
        "  X_train, y_train = df_to_X_y(df = train_data[\"R\"],\n",
        "                              window_size = d)\n",
        "\n",
        "  validation_data = df.iloc[end_train_index:end_valid_index].reset_index(drop=True)\n",
        "\n",
        "  X_validation, y_validation = df_to_X_y(df = validation_data[\"R\"],\n",
        "                              window_size = d)\n",
        "\n",
        "\n",
        "  return X_train, y_train, X_validation, y_validation, X_test, y_test\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VuN8Y4zNngYc"
      },
      "outputs": [],
      "source": [
        "# splitting thet data -> generating train/test/evaluation sets\n",
        "\n",
        "\n",
        "[X_train_GSPC,\n",
        "y_train_GSPC,\n",
        "X_validation_GSPC,\n",
        "y_validation_GSPC,\n",
        "X_test_GSPC,\n",
        "y_test_GSPC] = data_transform_split(df = Data[\"^GSPC\"],\n",
        "                                      test_start = test_start_date,\n",
        "                                      test_end=test_end_date)\n",
        "\n",
        "[X_train_FTSE,\n",
        "y_train_FTSE,\n",
        "X_validation_FTSE,\n",
        "y_validation_FTSE,\n",
        "X_test_FTSE,\n",
        "y_test_FTSE] = data_transform_split(df = Data[\"^FTSE\"],\n",
        "                                      test_start = test_start_date,\n",
        "                                      test_end=test_end_date)\n",
        "\n",
        "\n",
        "[X_train_EUSTOXX,\n",
        "y_train_EUSTOXX,\n",
        "X_validation_EUSTOXX,\n",
        "y_validation_EUSTOXX,\n",
        "X_test_EUSTOXX,\n",
        "y_test_EUSTOXX] = data_transform_split(df = Data[\"^STOXX50E\"],\n",
        "                                      test_start = test_start_date,\n",
        "                                      test_end=test_end_date)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IufLsdIllB8v"
      },
      "source": [
        "## LSTM-Mixed Density Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJQPRDBcattV"
      },
      "source": [
        "### Model Building\n",
        "1. LSTM-MDN with 2-component MDN layer\n",
        "2. LSTM-MDN with 2-component MDN layer & regularized loss function\n",
        "3. LSTM-MDN with 3-component MDN layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "O8zLFYjZmxEG"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Model 1: 2-component MDN (vanilla model)\n",
        "Architecture\n",
        "6 Neurons in LSTM Layer\n",
        "10 Neurons in Hidden Layer\n",
        "2 components for Gaussian Mixture\n",
        "\n",
        "Loss function: mean negative log-likelihood loss of y given the mixture parameters\n",
        "Optimizer: Adam with learning rate of 0.001\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"S&P500\"\n",
        "model_plain_GSPC = Sequential()\n",
        "model_plain_GSPC.add(InputLayer(input_shape = (d,1)))\n",
        "model_plain_GSPC.add(LSTM(6, activation = \"relu\"))\n",
        "model_plain_GSPC.add(Dense(10, activation = \"relu\"))\n",
        "model_plain_GSPC.add(mdn.MDN(output_dimension = 1,\n",
        "                  num_mixtures = 2))\n",
        "\n",
        "# compiling model\n",
        "# using neg. log lik as loss\n",
        "model_plain_GSPC.compile(loss=mdn.get_mixture_loss_func(1,2),\n",
        "                         optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "\"FTSE\"\n",
        "model_plain_FTSE = Sequential()\n",
        "model_plain_FTSE.add(InputLayer(input_shape = (d,1)))\n",
        "model_plain_FTSE.add(LSTM(6, activation = \"relu\"))\n",
        "model_plain_FTSE.add(Dense(10, activation = \"relu\"))\n",
        "model_plain_FTSE.add(mdn.MDN(output_dimension = 1,\n",
        "                  num_mixtures = 2))\n",
        "\n",
        "# compiling model\n",
        "# using neg. log lik as loss\n",
        "model_plain_FTSE.compile(loss=mdn.get_mixture_loss_func(1,2),\n",
        "                         optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\"EUROSTOXX50\"\n",
        "model_plain_EUSTOXX = Sequential()\n",
        "model_plain_EUSTOXX.add(InputLayer(input_shape = (d,1)))\n",
        "model_plain_EUSTOXX.add(LSTM(6, activation = \"relu\"))\n",
        "model_plain_EUSTOXX.add(Dense(10, activation = \"relu\"))\n",
        "model_plain_EUSTOXX.add(mdn.MDN(output_dimension = 1,\n",
        "                  num_mixtures = 2))\n",
        "\n",
        "# compiling model\n",
        "# using neg. log lik as loss\n",
        "model_plain_EUSTOXX.compile(loss=mdn.get_mixture_loss_func(1,2),\n",
        "                         optimizer=keras.optimizers.Adam())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LZTbCqOKXipf"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Model 2: 2-component MDN w/ regularized loss function\n",
        "Architecture\n",
        "6 Neurons in LSTM Layer\n",
        "10 Neurons in Hidden Layer\n",
        "2 components for Gaussian Mixture\n",
        "\n",
        "Loss function: REGULARIZED (L2-norm) mean negative log-likelihood loss of y given the mixture parameters\n",
        "Optimizer: Adam with learning rate of 0.001\n",
        "\"\"\"\n",
        "\n",
        "\"S&P500\"\n",
        "model_regularized_GSPC = Sequential()\n",
        "model_regularized_GSPC.add(InputLayer(input_shape = (d,1)))\n",
        "model_regularized_GSPC.add(LSTM(6, activation = \"relu\"))\n",
        "model_regularized_GSPC.add(Dense(10, activation = \"relu\"))\n",
        "model_regularized_GSPC.add(mdn.MDN(output_dimension = 1,\n",
        "                  num_mixtures = 2))\n",
        "\n",
        "\n",
        "# compiling model\n",
        "# using REGULARIZED neg. log lik as loss\n",
        "model_regularized_GSPC.compile(loss=get_mixture_loss_func_REGULARIZED(1,2, lambda_reg=0.1),\n",
        "                         optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\"FTSE\"\n",
        "model_regularized_FTSE = Sequential()\n",
        "model_regularized_FTSE.add(InputLayer(input_shape = (d,1)))\n",
        "model_regularized_FTSE.add(LSTM(6, activation = \"relu\"))\n",
        "model_regularized_FTSE.add(Dense(10, activation = \"relu\"))\n",
        "model_regularized_FTSE.add(mdn.MDN(output_dimension = 1,\n",
        "                  num_mixtures = 2))\n",
        "\n",
        "# compiling model\n",
        "# using REGULARIZED neg. log lik as loss\n",
        "model_regularized_FTSE.compile(loss=get_mixture_loss_func_REGULARIZED(1,2, lambda_reg=0.1),\n",
        "                         optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "\"EUROSTOXX50\"\n",
        "model_regularized_EUSTOXX = Sequential()\n",
        "model_regularized_EUSTOXX.add(InputLayer(input_shape = (d,1)))\n",
        "model_regularized_EUSTOXX.add(LSTM(6, activation = \"relu\"))\n",
        "model_regularized_EUSTOXX.add(Dense(10, activation = \"relu\"))\n",
        "model_regularized_EUSTOXX.add(mdn.MDN(output_dimension = 1,\n",
        "                  num_mixtures = 2))\n",
        "\n",
        "\n",
        "# compiling model\n",
        "# using REGULARIZED neg. log lik as loss\n",
        "model_regularized_EUSTOXX.compile(loss=get_mixture_loss_func_REGULARIZED(1,2, lambda_reg=0.1),\n",
        "                         optimizer=keras.optimizers.Adam())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "624GMQJrGjHi"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Model 3: 3-component MDN\n",
        "Architecture\n",
        "6 Neurons in LSTM Layer\n",
        "10 Neurons in Hidden Layer\n",
        "3 components for Gaussian Mixture\n",
        "\n",
        "Loss function: mean negative log-likelihood loss of y given the mixture parameters\n",
        "Optimizer: Adam with learning rate of 0.001\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\"GSPC\"\n",
        "model_C3_GSPC = Sequential()\n",
        "model_C3_GSPC.add(InputLayer(input_shape = (d,1)))\n",
        "model_C3_GSPC.add(LSTM(6, activation = \"relu\"))\n",
        "model_C3_GSPC.add(Dense(10, activation = \"relu\"))\n",
        "model_C3_GSPC.add(mdn.MDN(output_dimension = 1,\n",
        "                  num_mixtures = 3))\n",
        "\n",
        "\n",
        "# compiling model\n",
        "model_C3_GSPC.compile(loss=mdn.get_mixture_loss_func(1, 3),\n",
        "                         optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\"FTSE\"\n",
        "model_C3_FTSE = Sequential()\n",
        "model_C3_FTSE.add(InputLayer(input_shape = (d,1)))\n",
        "model_C3_FTSE.add(LSTM(6, activation = \"relu\"))\n",
        "model_C3_FTSE.add(Dense(10, activation = \"relu\"))\n",
        "model_C3_FTSE.add(mdn.MDN(output_dimension = 1,\n",
        "                  num_mixtures = 3))\n",
        "\n",
        "# compiling model\n",
        "model_C3_FTSE.compile(loss=mdn.get_mixture_loss_func(1, 3),\n",
        "                         optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"EUROSTOXX 50\"\n",
        "model_C3_EUSTOXX = Sequential()\n",
        "model_C3_EUSTOXX.add(InputLayer(input_shape = (d,1)))\n",
        "model_C3_EUSTOXX.add(LSTM(6, activation = \"relu\"))\n",
        "model_C3_EUSTOXX.add(Dense(10, activation = \"relu\"))\n",
        "model_C3_EUSTOXX.add(mdn.MDN(output_dimension = 1,\n",
        "                  num_mixtures = 3))\n",
        "\n",
        "# compiling model\n",
        "model_C3_EUSTOXX.compile(loss=mdn.get_mixture_loss_func(1, 3),\n",
        "                         optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxyjY19nSMYn"
      },
      "source": [
        "Model Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sZVaqje03VB",
        "outputId": "b2723df9-028d-4d9f-e31f-73fde47bd561"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7dbd384237c0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\"fitting models for S&P500\"\n",
        "\n",
        "\"vanilla model\"\n",
        "model_plain_GSPC.fit(X_train_GSPC, y_train_GSPC,\n",
        "                     validation_data=(X_validation_GSPC,y_validation_GSPC),\n",
        "                     epochs = 100,\n",
        "                     callbacks = [mon, tensorboard],\n",
        "                     verbose = 0)\n",
        "\n",
        "\"regularized model\"\n",
        "model_regularized_GSPC.fit(X_train_GSPC, y_train_GSPC,\n",
        "                           validation_data=(X_validation_GSPC,y_validation_GSPC),\n",
        "                           epochs = 100,\n",
        "                           callbacks = [mon, tensorboard],\n",
        "                            verbose = 0)\n",
        "\n",
        "\"3-component model\"\n",
        "model_C3_GSPC.fit(X_train_GSPC, y_train_GSPC,\n",
        "                  validation_data=(X_validation_GSPC,y_validation_GSPC),\n",
        "                  epochs = 100,\n",
        "                  callbacks = [mon, tensorboard],\n",
        "                  verbose = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xs-HBcXUWIiM",
        "outputId": "e07ffbd7-6f11-4212-ce59-7deb8d800246"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7dbd2667ba60>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "\"fitting models for FTSE\"\n",
        "\n",
        "\"vanilla model\"\n",
        "model_plain_FTSE.fit(X_train_FTSE, y_train_FTSE,\n",
        "                     validation_data=(X_validation_FTSE,y_validation_FTSE),\n",
        "                     epochs = 100,\n",
        "                     callbacks = [mon, tensorboard],\n",
        "                     verbose = 0)\n",
        "\n",
        "\"regularized model\"\n",
        "model_regularized_FTSE.fit(X_train_FTSE, y_train_FTSE,\n",
        "                           validation_data=(X_validation_FTSE,y_validation_FTSE),\n",
        "                           epochs = 100,\n",
        "                           callbacks = [mon, tensorboard],\n",
        "                            verbose = 0)\n",
        "\n",
        "\"3-component model\"\n",
        "model_C3_FTSE.fit(X_train_FTSE, y_train_FTSE,\n",
        "                  validation_data=(X_validation_FTSE,y_validation_FTSE),\n",
        "                  epochs = 100,\n",
        "                  callbacks = [mon, tensorboard],\n",
        "                  verbose = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeuOVK3aWRTp",
        "outputId": "f8765c97-4d22-4bf9-843b-56f265251572"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7dbd28d9bf10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "\"fitting models for EUROSTOXX50\"\n",
        "\n",
        "\"vanilla model\"\n",
        "model_plain_EUSTOXX.fit(X_train_EUSTOXX, y_train_EUSTOXX,\n",
        "                     validation_data=(X_validation_EUSTOXX,y_validation_EUSTOXX),\n",
        "                     epochs = 100,\n",
        "                     callbacks = [mon, tensorboard],\n",
        "                     verbose = 0)\n",
        "\n",
        "\"regularized model\"\n",
        "model_regularized_EUSTOXX.fit(X_train_EUSTOXX, y_train_EUSTOXX,\n",
        "                           validation_data=(X_validation_EUSTOXX,y_validation_EUSTOXX),\n",
        "                           epochs = 100,\n",
        "                           callbacks = [mon, tensorboard],\n",
        "                            verbose = 0)\n",
        "\n",
        "\"3-component model\"\n",
        "model_C3_EUSTOXX.fit(X_train_EUSTOXX, y_train_EUSTOXX,\n",
        "                  validation_data=(X_validation_EUSTOXX,y_validation_EUSTOXX),\n",
        "                  epochs = 100,\n",
        "                  callbacks = [mon, tensorboard],\n",
        "                  verbose = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5Q4ONCZZoTc"
      },
      "source": [
        "Model Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNb0m0xLaWoN",
        "outputId": "64a75a85-d9be-448e-9d2c-2d5f92d66fa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# running predictions and storing results in a data frame\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\"S&P 500\"\n",
        "GSPC_vanilla = dataframe_converter(predictions = MDN_predict(model = model_plain_GSPC,\n",
        "                                       test_data = X_test_GSPC,\n",
        "                                       N_MIXES=2),\n",
        "                                   N_MIXES = 2)\n",
        "\n",
        "\n",
        "GSPC_regularized = dataframe_converter(predictions = MDN_predict(model = model_regularized_GSPC,\n",
        "                                       test_data = X_test_GSPC,\n",
        "                                       N_MIXES=2),\n",
        "                                   N_MIXES = 2)\n",
        "\n",
        "\n",
        "GSPC_C3 = dataframe_converter(predictions = MDN_predict(model = model_C3_GSPC,\n",
        "                                       test_data = X_test_GSPC,\n",
        "                                       N_MIXES=3),\n",
        "                                   N_MIXES = 3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"FTSE\"\n",
        "FTSE_vanilla = dataframe_converter(predictions = MDN_predict(model = model_plain_FTSE,\n",
        "                                       test_data = X_test_FTSE,\n",
        "                                       N_MIXES=2),\n",
        "                                   N_MIXES = 2)\n",
        "\n",
        "\n",
        "FTSE_regularized = dataframe_converter(predictions = MDN_predict(model = model_regularized_FTSE,\n",
        "                                       test_data = X_test_FTSE,\n",
        "                                       N_MIXES=2),\n",
        "                                   N_MIXES = 2)\n",
        "\n",
        "\n",
        "FTSE_C3 = dataframe_converter(predictions = MDN_predict(model = model_C3_FTSE,\n",
        "                                       test_data = X_test_FTSE,\n",
        "                                       N_MIXES=3),\n",
        "                                   N_MIXES = 3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"EUROSTOXX50\"\n",
        "EUSTOXX_vanilla = dataframe_converter(predictions = MDN_predict(model = model_plain_EUSTOXX,\n",
        "                                       test_data = X_test_EUSTOXX,\n",
        "                                       N_MIXES=2),\n",
        "                                   N_MIXES = 2)\n",
        "\n",
        "\n",
        "EUSTOXX_regularized = dataframe_converter(predictions = MDN_predict(model = model_regularized_EUSTOXX,\n",
        "                                       test_data = X_test_EUSTOXX,\n",
        "                                       N_MIXES=2),\n",
        "                                   N_MIXES = 2)\n",
        "\n",
        "\n",
        "EUSTOXX_C3 = dataframe_converter(predictions = MDN_predict(model = model_C3_EUSTOXX,\n",
        "                                       test_data = X_test_EUSTOXX,\n",
        "                                       N_MIXES=3),\n",
        "                                   N_MIXES = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "q6RolVQRoMD0",
        "outputId": "6de4655e-db15-4e4a-b310-7de05b1925a8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_376076df-5f8c-45ac-b3c5-224c7f84e432\", \"GSPC_vanilla_covid.csv\", 37354)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_376cb48c-a272-44d2-88a9-b14ed7982be5\", \"GSPC_regularized_covid.csv\", 37755)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3150b12d-4897-4b1f-bfe0-a17e52efa4b7\", \"GSPC_C3_covid.csv\", 55979)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_531a679b-7dda-405f-9f80-1c4d8a105138\", \"FTSE_vanilla_covid.csv\", 37209)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_749a16fc-9650-4ac0-a14c-66a70a636b2b\", \"FTSE_regularized_covid.csv\", 38017)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fd0f4292-a6a5-42fa-a7b1-e85f94ab8bb9\", \"FTSE_C3_covid.csv\", 56776)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_79c84139-32b3-4b2f-8369-b34a668462f5\", \"EUSTOXX_vanilla_covid.csv\", 37709)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3ad040f1-ca3b-4052-b82c-8e7a6740a87b\", \"EUSTOXX_regularized_covid.csv\", 38360)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ece1508d-ef93-47cb-a34f-acecb90bcd52\", \"EUSTOXX_C3_covid.csv\", 56143)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\"\"\"\n",
        "DATA DOWNLOAD\n",
        "\"\"\"\n",
        "\n",
        "# if save_results == True, results data will be downloaded to local drive\n",
        "if save_results == True:\n",
        "\n",
        "  # results S&P\n",
        "  GSPC_vanilla.to_csv('GSPC_vanilla'+ period_appendix +'.csv', encoding = 'utf-8-sig')\n",
        "  files.download('GSPC_vanilla'+ period_appendix +'.csv')\n",
        "\n",
        "  GSPC_regularized.to_csv('GSPC_regularized'+ period_appendix +'.csv', encoding = 'utf-8-sig')\n",
        "  files.download('GSPC_regularized'+ period_appendix +'.csv')\n",
        "\n",
        "  GSPC_C3.to_csv('GSPC_C3'+ period_appendix +'.csv', encoding = 'utf-8-sig')\n",
        "  files.download('GSPC_C3'+ period_appendix +'.csv')\n",
        "\n",
        "  # results FTSE\n",
        "  FTSE_vanilla.to_csv('FTSE_vanilla'+ period_appendix +'.csv', encoding = 'utf-8-sig')\n",
        "  files.download('FTSE_vanilla'+ period_appendix +'.csv')\n",
        "\n",
        "  FTSE_regularized.to_csv('FTSE_regularized'+ period_appendix +'.csv', encoding = 'utf-8-sig')\n",
        "  files.download('FTSE_regularized'+ period_appendix +'.csv')\n",
        "\n",
        "  FTSE_C3.to_csv('FTSE_C3'+ period_appendix +'.csv', encoding = 'utf-8-sig')\n",
        "  files.download('FTSE_C3'+ period_appendix +'.csv')\n",
        "\n",
        "  # results EUROSTOXX50\n",
        "  EUSTOXX_vanilla.to_csv('EUSTOXX_vanilla'+ period_appendix +'.csv', encoding = 'utf-8-sig')\n",
        "  files.download('EUSTOXX_vanilla'+ period_appendix +'.csv')\n",
        "\n",
        "  EUSTOXX_regularized.to_csv('EUSTOXX_regularized'+ period_appendix +'.csv', encoding = 'utf-8-sig')\n",
        "  files.download('EUSTOXX_regularized'+ period_appendix +'.csv')\n",
        "\n",
        "  EUSTOXX_C3.to_csv('EUSTOXX_C3'+ period_appendix +'.csv', encoding = 'utf-8-sig')\n",
        "  files.download('EUSTOXX_C3'+ period_appendix +'.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Z_aOZodlDU-K"
      },
      "outputs": [],
      "source": [
        "# clearing & resetting tensorflow backend\n",
        "tf.keras.backend.clear_session()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}